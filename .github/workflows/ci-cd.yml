name: CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]

env:
  DOCKER_BUILDKIT: 1
  COMPOSE_DOCKER_CLI_BUILD: 1

jobs:
  build-and-test:
    runs-on: ubuntu-latest
    
    env:
      FLASK_ENV: development
      TESTING: "true"
      LOG_TO_FILE: "0"
      DISABLE_EXTRATO_BACKGROUND: "true"
      LOGIN_DISABLED: "false"
      # Test configuration for API integration tests
      DISABLE_AUTH_REDIRECTS: "1"
      RATE_LIMIT_ENABLED: "0"
      BASE_URL: "http://app:5000"
      # Database configuration (for both db and app services)
      POSTGRES_USER: ${{ secrets.POSTGRES_USER }}
      POSTGRES_PASSWORD: ${{ secrets.POSTGRES_PASSWORD }}
      POSTGRES_DB: ${{ secrets.POSTGRES_DB }}
      DATABASE_URL: postgresql://${{ secrets.POSTGRES_USER }}:${{ secrets.POSTGRES_PASSWORD }}@db:5432/${{ secrets.POSTGRES_DB }}
      # Application secrets
      FLASK_SECRET_KEY: ${{ secrets.CI_FLASK_SECRET_KEY }}
      JWT_SECRET_KEY: ${{ secrets.CI_JWT_SECRET_KEY }}
      JOTFORM_API_KEY: ${{ secrets.CI_JOTFORM_API_KEY }}
      JOTFORM_FORM_ID: ${{ secrets.CI_JOTFORM_FORM_ID }}
      GOOGLE_CLIENT_ID: ${{ secrets.CI_GOOGLE_CLIENT_ID }}
      GOOGLE_CLIENT_SECRET: ${{ secrets.CI_GOOGLE_CLIENT_SECRET }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
      
      - name: Create .env file for CI
        run: |
          echo "POSTGRES_USER=${{ secrets.POSTGRES_USER }}" >> .env
          echo "POSTGRES_PASSWORD=${{ secrets.POSTGRES_PASSWORD }}" >> .env
          echo "POSTGRES_DB=${{ secrets.POSTGRES_DB }}" >> .env
          echo "FLASK_SECRET_KEY=${{ secrets.CI_FLASK_SECRET_KEY }}" >> .env
          echo "JWT_SECRET_KEY=${{ secrets.CI_JWT_SECRET_KEY }}" >> .env
          echo "JOTFORM_API_KEY=${{ secrets.CI_JOTFORM_API_KEY }}" >> .env
          echo "JOTFORM_FORM_ID=${{ secrets.CI_JOTFORM_FORM_ID }}" >> .env
          echo "GOOGLE_CLIENT_ID=${{ secrets.CI_GOOGLE_CLIENT_ID }}" >> .env
          echo "GOOGLE_CLIENT_SECRET=${{ secrets.CI_GOOGLE_CLIENT_SECRET }}" >> .env
          echo "DISABLE_AUTH_REDIRECTS=1" >> .env
          echo "RATE_LIMIT_ENABLED=0" >> .env
          echo "BASE_URL=http://app:5000" >> .env
        working-directory: ${{ github.workspace }}
      
      - name: Build Docker images
        run: |
          echo "Building images with --no-cache to ensure fresh build"
          docker compose build --no-cache
      
      - name: Start services
        run: docker compose up -d
      
      - name: Wait for database to be healthy
        run: |
          echo "Waiting for PostgreSQL (tattoo_studio_db) to be healthy..."
          timeout 90 bash -c 'until [ "$(docker inspect -f {{.State.Health.Status}} tattoo_studio_db)" = "healthy" ]; do sleep 2; done'
          echo "PostgreSQL is ready - verifying with pg_isready..."
          docker compose exec -T db pg_isready -U ${{ secrets.POSTGRES_USER }} -d ${{ secrets.POSTGRES_DB }}
          echo "Database connection verified"
      
      - name: Set up backups directory permissions
        run: |
          echo "Setting up backups directory with write permissions..."
          mkdir -p backups
          chmod -R 777 backups
          echo "Backups directory permissions configured"
      
      - name: Reset database for clean test run
        run: |
          echo "Resetting database to ensure clean state..."
          docker compose exec -T db psql -U ${{ secrets.POSTGRES_USER }} -d postgres -c "DROP DATABASE IF EXISTS ${{ secrets.POSTGRES_DB }};"
          docker compose exec -T db psql -U ${{ secrets.POSTGRES_USER }} -d postgres -c "CREATE DATABASE ${{ secrets.POSTGRES_DB }};"
          echo "Database reset complete"
      
      - name: Ensure logs directory exists
        run: docker compose exec -T --user root app sh -c "mkdir -p /app/backend/logs && chown -R appuser:appuser /app/backend/logs"
      
      # Database schema is created automatically by tests (SQLite in-memory)
      # No need to call create_tables() in CI as it can cause UniqueViolation errors
      # Tests use their own isolated in-memory database configured in conftest.py

      - name: Run tests
        run: docker compose run --rm app pytest -v
      
      - name: Check logs for errors
        if: failure()
        run: docker compose logs
      
      - name: Stop services
        if: always()
        run: docker compose down -v

  lint:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install flake8 black
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
      
      - name: Lint with flake8
        run: |
          # Stop build if there are Python syntax errors or undefined names
          flake8 backend/app --count --select=E9,F63,F7,F82 --show-source --statistics
          # Exit-zero treats all errors as warnings
          flake8 backend/app --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics
      
      - name: Check code formatting with black
        run: |
          black --check backend/app

  security-scan:
    runs-on: ubuntu-latest
    
    permissions:
      contents: read
      security-events: write
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Run Trivy vulnerability scanner
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: 'fs'
          scan-ref: '.'
          format: 'sarif'
          output: 'trivy-results.sarif'
      
      - name: Upload Trivy results to GitHub Security tab
        uses: github/codeql-action/upload-sarif@v3
        if: always()
        with:
          sarif_file: 'trivy-results.sarif'
